[
  {
    "objectID": "scripts/06-practical.html",
    "href": "scripts/06-practical.html",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "",
    "text": "Residuals patterns in Surveillance data",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/06-practical.html#learn-6",
    "href": "scripts/06-practical.html#learn-6",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "Expected learning outcomes",
    "text": "Expected learning outcomes\nBy the end of this session, participants should be able to:\n\ndecide on remaining actions when modelling surveillance data after you have accounted for trend and periodicity\ndetect autocorrelation in the residuals of models on surveillance data",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/06-practical.html#task-6-1",
    "href": "scripts/06-practical.html#task-6-1",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "Task 6.1",
    "text": "Task 6.1\nStart by fitting the model with trend and two cosines and two sines. Assuming you are happy with that Poisson regression model from the previous session, check whether this regression model was appropriate in this case.\n\n\nShow the code\nload(here(\"data\",\"mortagg2_case_5.RData\"))\n\n\nStart by fitting the model with trend and two cosines and two sines.\nThen, assuming you are happy with that model, check whether this regression model was appropriate in this case.\nPlot the residuals from the model in case study 5 that included a trend, 52-week periodicity and 26-week periodicity.\n\n\nShow the code\nmortz &lt;-\n    mortz %&gt;%\n    mutate(res=residuals(mort_trendsin2cos2)\n    )\n\n\n\n\nShow the code\nggplot(data = mortz) +\n    geom_point(\n        mapping = aes(x = date_index, y = res)\n    ) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n    labs(x = \"Year week\", \n         y = \"Residuals\", \n         title = \"Spain: number of deaths. Residuals model trend + 2 sine + 2 cosine.\"\n    ) +\n    tsa_theme\n\n\n\n\n\n\n\n\n\nStart by examining the residuals against time. Do you see any additional patterns?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/06-practical.html#task-6-2",
    "href": "scripts/06-practical.html#task-6-2",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "Task 6.2",
    "text": "Task 6.2\nIs there any other periodicity that can be observed in the residuals?\nTo assess whether there is any more periodicity in the data, one can produce a periodogram of the residuals (use code from case study 5).\n\n\nShow the code\nmort_residual_period &lt;- TSA::periodogram(mortz$res)\n\n\n\n\n\n\n\n\n\nShow the code\nmort_residual_period_recip &lt;-\n    tibble(\n        freq = mort_residual_period$freq,\n        spec = mort_residual_period$spec\n    ) %&gt;%\n    arrange(desc(spec)) %&gt;% \n    mutate(reciprocal_freq = 1 / freq)  # here in weeks\n\nview(mort_residual_period_recip)\n\n# breaks every 13, equivalent to every 3 months approximately.\nggplot(data = mort_residual_period_recip, aes(x = reciprocal_freq, y = 2*spec)) +\n    geom_line() +\n    scale_x_continuous(limits = c(0, 160), breaks=seq(0, 160, 13)) +\n    labs(x = \"Period (weeks)\", \n         y = \"Spectral density\",\n         title=\"Periodogram residuals of model with trend + 2 sine + 2 cosine.\") +\n    tsa_theme\n\n\n\n\n\n\n\n\n\nPlot the residuals again, but now using lines.\n\n\nShow the code\nmax.index &lt;- max(mortz$index)\n\nggplot(data = mortz) +\n    geom_line(\n        mapping = aes(x = index, y = res)\n    ) +\n    labs(\n        x = \"Week\",\n        y = \"Residuals\",\n        title = \"Regression model with trend + 2 sine + 2 cosine.\"\n    ) +\n    scale_x_continuous(limits = c(0, max.index), breaks=seq(0, max.index, 77)) +\n    tsa_theme\n\n\n\n\n\n\n\n\n\nBased on these latest plots, do you see a patterns that can explain the periodogram? Does the periodicity makes sense in this case?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/06-practical.html#task-6-3",
    "href": "scripts/06-practical.html#task-6-3",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "Task 6.3 (Optional)",
    "text": "Task 6.3 (Optional)\nAs a sensitivity analysis, add yet one more lag (not significant in the acf) to the last model. Does that lag improve the model?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/06-practical.html#task-6-4",
    "href": "scripts/06-practical.html#task-6-4",
    "title": "Practical Session 6: Residuals and autocorrelation",
    "section": "Task 6.4 (Optional)",
    "text": "Task 6.4 (Optional)\nCarry out similar analyzes for men and for women.\n\n\nShow the code\n#save(mortagg, mortz, file = here(\"data\", \"mortagg2_case_6.RData\"))\n\n#load(here(\"data\",\"mortagg2_case_6.RData\"))",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 6: Residuals and autocorrelation"
    ]
  },
  {
    "objectID": "scripts/07-practical.html",
    "href": "scripts/07-practical.html",
    "title": "Practical Session 7: Forecasting",
    "section": "",
    "text": "Expected learning outcomes\nBy the end of this session, participants should be able to: - understand the use of forecasting in public health surveillance data - forecast the expected number of cases of a disease into the future",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#task-7-1",
    "href": "scripts/07-practical.html#task-7-1",
    "title": "Practical Session 7: Forecasting",
    "section": "Task 7.1",
    "text": "Task 7.1\nJanuary 2020: Your boss received a phone call from the Ministry of Health. She is part of a committee that is responsible for setting the alert levels for mortality in Spain for the next year (2020). Before doing so, she gives you the task to forecast the total expected number of deaths for 2020 based on the historical data up to and including 2019.",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#solution-7-1",
    "href": "scripts/07-practical.html#solution-7-1",
    "title": "Practical Session 7: Forecasting",
    "section": "Help for Task 7.1",
    "text": "Help for Task 7.1\n\n\nShow the code\nggplot(data = mortz) +\n    geom_line(\n        mapping = aes(x = year_week, y = cases),\n        colour = \"black\",\n        alpha = 1.2\n    ) +\n    geom_line(\n        mapping = aes(x = year_week, y = mort_sine2cos2trendmodel$fitted),\n        colour = \"red\",\n        alpha = 1.2\n    ) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"8 weeks\") +\n    labs(x = \"Year Week\", y = \"Weekly cases\") +\n    tsa_theme + \n    theme(axis.text.x = element_text(angle = 30, hjust = 1)) \n\n\n\n\n\n\n\n\n\nThe dataset has records up to 2019-W52, and you would like to project the data (forecast) into 2020.\nFirst, create a new time series object for 2020. Note that 2020 has 53 weeks.\n\n\nShow the code\npred.df &lt;-\n    tibble(\n        year=2020,\n        week  = 1:53,\n        index = 521:(521+53-1), # add 53 weeks\n        year_week = make_yearweek(year = year, week = week),\n        sin52 = sin(2 * pi * week / 52),\n        cos52 = cos(2 * pi * week / 52),\n        sin26 = sin(2 * pi * week / 26),\n        cos26 = cos(2 * pi * week / 26),\n        pop = 47318050) %&gt;%                # Spanish pop in 2020 (1st Jan)\n    as_tsibble(index = index)\n\nview(pred.df)\n\n\nCalculate the expected values and 95% prediction intervals for each week of 2020 assuming that the Poisson regression model with trend and 2 seasonality terms based on the previous years is appropriate.\nPredict and plot the expected number of deaths per week for 2020 with prediction intervals:\n\n\nShow the code\n# apply mort_sine2cos2trendmodel to new data and predict cases with C.I. using bootstrapping.\n# bootstrapping is a statistical method where you draw random samples from your data, \n# and analyze each of this samples.\n# https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n\n\nset.seed(12589)\npred.mort &lt;- ciTools::add_ci(pred.df,\n                            mort_sine2cos2trendmodel,\n                            names=c(\"lPI\", \"uPI\"),\n                            yhatName=\"pred_cases\",\n                            response=TRUE,\n                            type=\"boot\",\n                            nSims=1000)\nhead(pred.mort, 5)\n\n\n  year week index year_week     sin52     cos52     sin26     cos26      pop\n1 2020    1   521  2020 W01 0.1205367 0.9927089 0.2393157 0.9709418 47318050\n2 2020    2   522  2020 W02 0.2393157 0.9709418 0.4647232 0.8854560 47318050\n3 2020    3   523  2020 W03 0.3546049 0.9350162 0.6631227 0.7485107 47318050\n4 2020    4   524  2020 W04 0.4647232 0.8854560 0.8229839 0.5680647 47318050\n5 2020    5   525  2020 W05 0.5680647 0.8229839 0.9350162 0.3546049 47318050\n  pred_cases      lPI       uPI\n1   9668.633 9505.031  9847.676\n2   9816.630 9649.887 10004.593\n3   9917.123 9743.460 10116.956\n4   9965.433 9788.115 10167.868\n5   9959.873 9784.202 10162.163\n\n\n\n\nShow the code\nggplot(data = pred.mort) +\n    geom_line(\n        mapping = aes(x = year_week, y = pred_cases),\n        colour = \"red\",\n        alpha = 0.7\n    ) +\n    geom_ribbon(\n        mapping = aes(x = year_week, ymin = lPI, ymax = uPI),\n        fill = \"red\",\n        alpha = 0.1\n    ) +\n    scale_y_continuous(limits = c(0, NA)) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"4 weeks\") +\n    labs(x = \"Year Week\", y = \"Predicted weekly fatalities\") +\n    tsa_theme + \n    theme(axis.text.x = element_text(angle = 30, hjust = 1)) \n\n\n\n\n\n\n\n\n\nCalculate the total number of expected deaths in 2020 in Spain.\n\n\nShow the code\n# Total predicted cases in 2020, with lPI and uPI\npred.mort %&gt;% \n  summarise(\n    pred_cases_2020 = sum(pred_cases),\n    pred_cases_2020_lPI = sum(lPI),\n    pred_cases_2020_uPI = sum(uPI)\n  )\n\n\n  pred_cases_2020 pred_cases_2020_lPI pred_cases_2020_uPI\n1        441385.8            435448.6            447514.4",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#task-7-2",
    "href": "scripts/07-practical.html#task-7-2",
    "title": "Practical Session 7: Forecasting",
    "section": "Task 7.2 (Optional)",
    "text": "Task 7.2 (Optional)\nJanuary 2021: A committee member is interested to get a better understanding of when there were periods of unusually high excess mortality and asks you to provide an analysis that highlights the time when these occurred.",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#solution-7-2",
    "href": "scripts/07-practical.html#solution-7-2",
    "title": "Practical Session 7: Forecasting",
    "section": "Help for Task 7.2",
    "text": "Help for Task 7.2\nCUSUM (cumulative sum) is a graphical method that can be used to determine when there is a change in a process (all-cause mortality in this example). In TSA it can also be used to decide whether there is a need to revise the model e.g. include a covariate or there have been changes in the seasonality.\nUsing expected values from the previous regression model, you can calculate the cumulative sum of the differences between the weekly observed and expected numbers of deaths:\n\n\nShow the code\nmortz &lt;- mortz %&gt;%\n  mutate(fit_cases = mort_sine2cos2trendmodel$fit,  # get predicted cases\n         \n         # calculate differences\n         difference = cases - fit_cases,\n         cumsum_excess = cumsum(difference),\n         diff_zero = cases - mean(fit_cases),\n         cumsum_zero = cumsum(diff_zero))\n\n\nPlot this cumulative sum of the residuals.\n\n\nShow the code\nggplot(data = mortz) +\ngeom_line(\n        mapping = aes(x = year_week, y = diff_zero),\n        colour = \"green\",\n        alpha = 0.7,\n        lwd = 2\n    ) +\n    geom_line(\n        mapping = aes(x = year_week, y = cumsum_zero),\n        colour = \"orange\",\n        alpha = 0.7,\n        lwd = 2\n    ) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"1 year\") +\n    labs(x = \"Year\", y = \"Cumulative excess cases\") +\n    tsa_theme",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#task-7-3",
    "href": "scripts/07-practical.html#task-7-3",
    "title": "Practical Session 7: Forecasting",
    "section": "Task 7.3 (Optional)",
    "text": "Task 7.3 (Optional)\nJanuary 2021: your boss needs to inform the Ministry of Health about excess deaths so far during the first year of the pandemic.",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/07-practical.html#solution-7-3",
    "href": "scripts/07-practical.html#solution-7-3",
    "title": "Practical Session 7: Forecasting",
    "section": "Help for Task 7.3",
    "text": "Help for Task 7.3\nPlot the actual number of deaths and compare with the predictions from the model based on 2010-2019.\n\n\nShow the code\n# load mortality data for 2020\nmort2020 &lt;- import(here(\"data\", \"mortagg2020.csv\"))\n\n# order mort2020 from week 1 to week 53, same as in pred.mort\nmort2020 &lt;- mort2020 %&gt;% arrange(week)\n\n# add actual deaths from 2020 in pred.mort\npred.mort &lt;- pred.mort %&gt;% \n  mutate(cases = mort2020$cases)\n\nggplot(data = pred.mort) +\n    geom_line(\n        mapping = aes(x = year_week, y = pred_cases),\n        colour = \"red\",\n        alpha = 0.7,\n        lwd = 1.2\n    ) +\n    geom_ribbon(\n        mapping = aes(x = year_week, ymin = lPI, ymax = uPI),\n        fill = \"red\",\n        alpha = 0.1\n    ) +\n    geom_line(\n        mapping = aes(x = year_week, y = cases),\n        colour = \"black\",\n        alpha = 0.7,\n        lwd = 1.2\n    ) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"4 weeks\") +\n    labs(x = \"Year Week\", y = \"Predicted weekly cases\") +\n    tsa_theme + \n    theme(axis.text.x = element_text(angle = 30, hjust = 1)) \n\n\n\n\n\n\n\n\n\nExcess deaths can be calculated as the difference of the actual number of fatalities per week and the predicted mean, or the predicted upper 95% PI.\n\n\nShow the code\npred.mort &lt;- pred.mort %&gt;%\n  mutate(\n    difference_mean = cases - pred_cases,\n    cusum_excess_mean = cumsum(difference_mean),\n    difference_uPI = cases - uPI,\n    cusum_excess_uPI = cumsum(difference_uPI)\n  )\n\n\nggplot(data = pred.mort) +\n    geom_line(\n        mapping = aes(x = year_week, y = cusum_excess_mean),\n        colour = \"orange\",\n        alpha = 0.7,\n        lwd = 2\n    ) +\n    geom_line(\n        mapping = aes(x = year_week, y = cusum_excess_uPI),\n        colour = \"blue\",\n        alpha = 0.7,\n        lwd = 2\n    ) +   \n    #scale_y_continuous(limits = c(-100, NA)) +\n    scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"4 weeks\") +\n    labs(x = \"Year\", y = \"Cumulative excess cases\") +\n    tsa_theme\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# save(list = ls(pattern = 'mort'), file = here(\"data\", \"mortagg2_case_7.RData\"))\n#load(here(\"data\",\"mortagg2_case_7.RData\"))",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 7: Forecasting"
    ]
  },
  {
    "objectID": "scripts/09-practical.html",
    "href": "scripts/09-practical.html",
    "title": "Practical Session 9: The relation between two time series",
    "section": "",
    "text": "Expected learning outcomes\nBy the end of this session, participants should be able to:",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/09-practical.html#learn-9",
    "href": "scripts/09-practical.html#learn-9",
    "title": "Practical Session 9: The relation between two time series",
    "section": "",
    "text": "assess and interpret associations with external variables\nidentify and interpret effect modification between external variables and the outcome variable in surveillance data",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/09-practical.html#task-9-1",
    "href": "scripts/09-practical.html#task-9-1",
    "title": "Practical Session 9: The relation between two time series",
    "section": "Task 9.1",
    "text": "Task 9.1\nUsing the aragon dataset, assess the effect of ambient temperature (using average weekly maximum temperature) on mortality in the autonomous community of Aragón. Is this effect uniform throughout the year?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/09-practical.html#solution-9-1",
    "href": "scripts/09-practical.html#solution-9-1",
    "title": "Practical Session 9: The relation between two time series",
    "section": "Help for Task 9.1",
    "text": "Help for Task 9.1\nOpen the dataset aragon.csv. There you will find mean maximum temperature and mortality data for the autonomous community of Aragon by week.\n\n\nShow the code\naragon &lt;- import(here(\"data\", \"aragon.csv\")) \n\n\nConvert the data to a time series and plot both variables (weekly mean maximum temperature and mortality data).\n\n\nShow the code\n# Create ts dataframe with yearweek index\naragonz &lt;- aragon %&gt;% \n  mutate(\n    year_week = make_yearweek(year = year, week = week),\n    index = seq.int(from = 1, to = nrow(aragon))\n  ) %&gt;% \n  as_tsibble(index = index)\n\n# Temperature plot   \naragonz_tmax_plot &lt;- ggplot(data = aragonz) +\n  geom_point(mapping = aes(x = year_week, y = tmax), colour = \"blue\", alpha = 0.5) +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(x = \"Week\", \n       y = \"Maximum Temperature\") +\n  tsa_theme\n\n# Mortality plot\naragonz_cases_plot &lt;- ggplot(data = aragonz) +\n  geom_point(mapping = aes(x = year_week, y = cases), colour = \"green\", alpha = 0.5) +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(x = \"Week\", \n       y = \"Weekly case counts\") +\n  tsa_theme\n\n# Using patchwork to join the two plots\n# The \"/\" determines an above/below display\naragonz_two_plot &lt;- (aragonz_tmax_plot / aragonz_cases_plot) \naragonz_two_plot\n\n\n\n\n\n\n\n\n\nGenerate variables for sine and cosine for annual oscillation.\n\n\nShow the code\naragonz &lt;- aragonz %&gt;% \n  mutate(sin52 = sin(2 * pi * date / 52),\n         cos52 = cos(2 * pi * date / 52))\n\n\nFit a poisson regression model with a simple trend to the weekly number of deaths, accounting for seasonality.\n\n\nShow the code\naragmodel1 &lt;- glm(cases ~ index + sin52 + cos52,\n                           family = \"poisson\",\n                           data = aragonz)\n\nsummary(aragmodel1)\n\n\n\nCall:\nglm(formula = cases ~ index + sin52 + cos52, family = \"poisson\", \n    data = aragonz)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 5.252e+00  6.312e-03 832.117  &lt; 2e-16 ***\nindex       1.260e-04  2.082e-05   6.052 1.43e-09 ***\nsin52       4.442e-02  4.426e-03  10.037  &lt; 2e-16 ***\ncos52       1.038e-01  4.417e-03  23.500  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1726.7  on 519  degrees of freedom\nResidual deviance: 1046.5  on 516  degrees of freedom\nAIC: 4756.3\n\nNumber of Fisher Scoring iterations: 4\n\n\nPlot the predicted weekly number of deaths.\n\n\nShow the code\nggplot(data = aragonz) +\n  geom_point(mapping = aes(x = year_week, y = cases), alpha = 0.2) +\n  geom_line(mapping = aes(x = year_week, y = aragmodel1$fitted.values), \n            colour = \"darkorange\", \n            alpha = 0.7, \n            lwd = 1.5) +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(x = \"Week\", \n       y = \"Weekly case counts\", \n       title = \"Cases with fitted trend\") +\n  tsa_theme\n\n\n\n\n\n\n\n\n\nDiscuss how your model fits the data.\nNote: When you plotted the weekly number of deaths in Aragon, perhaps you noticed that mortality peaks in winter; however, there are smaller peaks during the summer, too. You can account for that in two different ways: a) include two sine/cosine functions in the model (one for 52-week cycles and one for 26-week cycles), or b) take into account the fact that temperature might be behaving differently as a risk factor in winter than it does in summer (sign of effect modification?).\nYou decide to perform your analysis twice; once for winter and once for the rest of the time. You define winter as the time between weeks 49 and 8.\n\n\nShow the code\naragonz &lt;- aragonz %&gt;% \n    mutate(winter = (week &gt;= 49 | week &lt;= 8))\n\n\nFirst run the model including winter as a main effect, and then including an interaction term with temperature.\n\n\nShow the code\n# Model with only main effect\naragmodel2 &lt;- glm(cases ~ index + sin52 + cos52 + winter,\n                           family = \"poisson\",\n                           data = aragonz)\n\n# Model with temperature interaction\naragmodel3 &lt;- glm(cases ~ index + sin52 + cos52 + winter * tmax,\n                           family = \"poisson\",\n                           data = aragonz)\n\n\nWe compare both model’s AIC below.\n\n\nShow the code\n# Easiest, most direct way\nAIC(aragmodel2); AIC(aragmodel3)\n\n\nWe can also create a fancier table using the library gtsummary like in practical 4. We use again exponentiate = T to exponentiate coefficients and style_number() to specify the number of digits. In addition, we use one extra argument: add_glance_table() allows to add key parameters at the bottom of the table. And table_merge() allows to take several tables built with tbl_regression and put them in one big table. This makes it easy to compare models.\n\n\nShow the code\ntbl_m2 &lt;- aragmodel2 %&gt;% \n  tbl_regression(exponentiate = TRUE,\n                 estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  add_glance_table(include = c(AIC, BIC, deviance))\n\ntbl_m3 &lt;- aragmodel3 %&gt;% \n  tbl_regression(exponentiate = TRUE,\n                 estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  add_glance_table(include = c(AIC, BIC, deviance))\n\ntbl_m2m3 &lt;- \n  tbl_merge(\n    tbls = list(tbl_m2, tbl_m3),\n    tab_spanner = c(\"aragmodel2\", \"aragmodel3\")\n  )\ntbl_m2m3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\naragmodel2\n\n\naragmodel3\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0001\n1.0001, 1.0002\n&lt;0.001\n1.0001\n1.0001, 1.0002\n&lt;0.001\n\n\nsin52\n1.0403\n1.0311, 1.0495\n&lt;0.001\n1.0621\n1.0508, 1.0735\n&lt;0.001\n\n\ncos52\n1.0783\n1.0651, 1.0917\n&lt;0.001\n1.1721\n1.1385, 1.2066\n&lt;0.001\n\n\nwinter\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    FALSE\n—\n—\n\n\n—\n—\n\n\n\n\n    TRUE\n1.0673\n1.0461, 1.0889\n&lt;0.001\n1.2688\n1.2020, 1.3392\n&lt;0.001\n\n\nAIC\n4,718\n\n\n\n\n4,666\n\n\n\n\n\n\nBIC\n4,739\n\n\n\n\n4,696\n\n\n\n\n\n\nDeviance\n1,006\n\n\n\n\n950\n\n\n\n\n\n\ntmax\n\n\n\n\n\n\n1.0078\n1.0054, 1.0103\n&lt;0.001\n\n\nwinter * tmax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    TRUE * tmax\n\n\n\n\n\n\n0.9849\n0.9806, 0.9893\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nNote that winter * tmax tells R to include terms in the model for winter, tmax and for their interaction. If we just wanted to include the interaction term without its corresponding “main effects”, i.e. without winter or tmax, we would use winter:tmax instead.\nDiscuss the output of the two models. Does the interpretation change when winter is taken into account as an interaction term along with temperature?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/09-practical.html#task-9-2",
    "href": "scripts/09-practical.html#task-9-2",
    "title": "Practical Session 9: The relation between two time series",
    "section": "Task 9.2 (Optional)",
    "text": "Task 9.2 (Optional)\nIt has been argued by experts that low temperatures in winter might be “slow killers”; that is, very low temperatures in winter do not result in a peak in mortality on the same day/week as they are observed, but rather after some time has elapsed. On the other hand, very high temperatures in summer are “fast killers”; they are associated with peaks in mortality very fast, i.e. heat waves kill people fast. Can you find evidence for this for Aragón?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/09-practical.html#solution-9-2",
    "href": "scripts/09-practical.html#solution-9-2",
    "title": "Practical Session 9: The relation between two time series",
    "section": "Help for Task 9.2",
    "text": "Help for Task 9.2\nIt has been argued by experts that low temperatures in winter might be “slow killers”; that would mean that very low temperatures in winter do not result in a peak in mortality on the same day/week when they are observed, but rather after some time. On the other hand, very high temperatures in summer are fast killers; they are associated with peaks in mortality very fast, i.e. heat waves kill people fast.\nFor this reason, you decide to check whether temperature has an effect on mortality with some lag. stats::lag is the default base R function to compute lags from the stats package. In the example below, we prefer to use one of the tidyverse package alternatives,namely dplyr::lag. We specify the package name here to avoid possible conflicts with other packages which have a lag function.\nWe are using the lag function from the dplyr package. For a given week, the value of tmax is lagged by 1 in respect to the previous week’s value.\n\n\nShow the code\n# Create lag variable\naragonz &lt;- aragonz %&gt;% \n  mutate(L1.tmax = dplyr::lag(x = tmax, n = 1))\n\n\nCreate a new model named aragmodel4 including the lag variable, and compare it with the previous model aragmodel3. What can you conclude from it?\n\n\nShow the code\naragmodel4 &lt;- glm(cases ~ index + sin52 + cos52 + winter * tmax + L1.tmax,\n                           family = \"poisson\",\n                           data = aragonz)\n\nsummary(aragmodel4)\n\n\n\nCall:\nglm(formula = cases ~ index + sin52 + cos52 + winter * tmax + \n    L1.tmax, family = \"poisson\", data = aragonz)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      5.087e+00  3.198e-02 159.076  &lt; 2e-16 ***\nindex            1.246e-04  2.097e-05   5.942 2.81e-09 ***\nsin52            5.679e-02  6.343e-03   8.954  &lt; 2e-16 ***\ncos52            1.504e-01  1.663e-02   9.043  &lt; 2e-16 ***\nwinterTRUE       2.268e-01  2.795e-02   8.113 4.94e-16 ***\ntmax             8.194e-03  1.304e-03   6.283 3.32e-10 ***\nL1.tmax         -1.226e-03  1.146e-03  -1.070    0.285    \nwinterTRUE:tmax -1.433e-02  2.278e-03  -6.291 3.15e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1708.45  on 518  degrees of freedom\nResidual deviance:  943.72  on 511  degrees of freedom\n  (1 observation deleted due to missingness)\nAIC: 4654.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nShow the code\nAIC(aragmodel3); AIC(aragmodel4)\n\n\n[1] 4665.836\n\n\n[1] 4654.111\n\n\nInstead of running the model with an interaction term, you could run the analyses for winter and the rest of your dataset separately.\nThe interaction term was not significant, but you are still curious about the differential effect of temperatures on mortality in winter and the other seasons. You decide to split the data and run two different models for winter and non-winter mortality and temperatures, and compare them.\nThink carefully about how you will compare them: are theAIC criteria still valid for this task?\n\n\nShow the code\n## winter subset\naragonz.winter &lt;- \n    aragonz %&gt;% \n    filter(winter == TRUE)\n\n## not winter subset\naragonz.notwinter &lt;- \n    aragonz %&gt;% \n    filter(winter == FALSE)\n\n\n\n\nShow the code\n# Winter model\naragmodel5 &lt;- glm(cases ~ index + sin52 + cos52 + L1.tmax,\n                           family = \"poisson\",\n                           data = aragonz.winter)\n\n# Not winter model\naragmodel6 &lt;- glm(cases ~ index + sin52 + cos52 + L1.tmax,\n                           family = \"poisson\",\n                           data = aragonz.notwinter)\n\n# Table summaries\ntbl_m5 &lt;- aragmodel5 %&gt;% \n  tbl_regression(exponentiate = TRUE,\n                 estimate_fun = ~style_number(.x, digits = 4))\n\ntbl_m6 &lt;- aragmodel6 %&gt;% \n  tbl_regression(exponentiate = TRUE,\n                 estimate_fun = ~style_number(.x, digits = 4))\n\n# Comparison table\ntbl_m5m6 &lt;- \n  tbl_merge(\n    tbls = list(tbl_m5, tbl_m6),\n    tab_spanner = c(\"Winter model\", \"Not winter model\")\n  )\ntbl_m5m6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nWinter model\n\n\nNot winter model\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0002\n1.0001, 1.0003\n&lt;0.001\n1.0001\n1.0001, 1.0002\n&lt;0.001\n\n\nsin52\n1.1944\n1.1428, 1.2486\n&lt;0.001\n1.0485\n1.0348, 1.0624\n&lt;0.001\n\n\ncos52\n1.7229\n1.4361, 2.0675\n&lt;0.001\n1.1094\n1.0785, 1.1412\n&lt;0.001\n\n\nL1.tmax\n0.9923\n0.9879, 0.9967\n&lt;0.001\n1.0031\n1.0006, 1.0055\n0.015\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nDiscuss the output of the different models. Which one would you go for?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 9: The relation between two time series"
    ]
  },
  {
    "objectID": "scripts/10-practical.html",
    "href": "scripts/10-practical.html",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "",
    "text": "Expected learning outcomes\nBy the end of the case study, participants will be able to:",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#learn-10",
    "href": "scripts/10-practical.html#learn-10",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "",
    "text": "Assess and interpret the effect of an intervention on trends and periodicity in surveillance data",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#description-of-the-dataset",
    "href": "scripts/10-practical.html#description-of-the-dataset",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "Description of the dataset",
    "text": "Description of the dataset\nRotavirus is a very common and potentially serious infection of the large bowel, mainly affecting young babies. Nearly every child will have at least one episode of rotavirus gastroenteritis by five years of age. People of any age can be affected, but the illness is more severe in young infants. The rotavirus immunisation programme was introduced in the UK on 1 July 2013 (week 27) with the objective of preventing a significant number of young infants from developing rotavirus infection. It may also provide some additional protection to the wider population through herd immunity. The aim of the rotavirus immunisation programme is to provide two doses of vaccine to infants from six weeks of age and before 24 weeks of age. The first dose of vaccine is offered at approximately eight weeks of age and the second dose at least four weeks after the first dose.\nHigh coverage was rapidly achieved for the first cohort of children offered rotavirus vaccine routinely in England and this has been maintained throughout the first fourteen months of the routine programme. Over this period, rotavirus vaccine coverage for children in the routine cohort averaged 93.3% for one dose and 88.3% for two doses.1",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#task-10-1",
    "href": "scripts/10-practical.html#task-10-1",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "Task 10.1",
    "text": "Task 10.1\nYou have been given a dataset for notified Rotavirus infections in England and Wales from week 23/2009 up to week 42/2018 (rotavirus.csv).\nAssess the impact of the introduction of the vaccination scheme in England and Wales for the whole population. Has the vaccine introduction had an effect on trend or periodicity patterns? Has the vaccine introduction affected the timing of the yearly outbreaks?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#solution-10-1",
    "href": "scripts/10-practical.html#solution-10-1",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "Help for Task 10.1",
    "text": "Help for Task 10.1\nOpen the rotavirus dataset, which is a line list of all notified rotavirus infections in the UK between June 2009 and December 2014. Prepare your data and test if the introduction of the vaccine has had an impact on the notified number of cases of rotavirus infections in the UK. Has the trend changed? Has the periodicity changed?\nPrepare the rotavirus.csv for time-series analysis. You need to manipulate the dataset before being able to use it for time series analysis.\n\n\nShow the code\nrota &lt;- import(here(\"data\", \"rotavirus.csv\")) \nview(rota)\n\n\nAs the data in rota shows above, this dataset is structured in a “wide” format. You can see two variables representing dates, and all other variables containing case counts are organised horizontally. Alternatively, we can store the same information by converting the first dataset to a “long” format, where one variable contains the different age group categories of cases (cases_cat), and another displays the corresponding case counts (n) for each age group and year-week.\nIn order to use ggplot2, remember that the data should be organised in a long format.\nThe function as_tsibble() is what indicates to R that the data is a time series. index represents the time variable and key represents the outcome studied.\n\n\nShow the code\n## convert to long format\nrota_lg &lt;- rota %&gt;% \n    pivot_longer(\n      cols = -c(year, week),\n      names_to = \"cases_cat\",\n      values_to = \"n\"\n    )\n\n## recode\nrota_lg &lt;- rota_lg %&gt;%\n  mutate(cases_cat = case_when(\n    cases_cat == \"case1\" ~ \"Cases &lt;1 year\",\n    cases_cat == \"case2\" ~ \"Cases 1 to 4 years\",\n    cases_cat == \"case3\" ~ \"Cases 5 to 14 years\",\n    cases_cat == \"case4\" ~ \"Cases 15 to 64 years\",\n    cases_cat == \"case5\" ~ \"Cases 65+ years\",\n    cases_cat == \"cases\" ~ \"Total cases\",\n    TRUE ~ NA_character_\n    ))\n\n## turn into ts format\nrota_lg &lt;- rota_lg %&gt;%\n  mutate(year_week = make_yearweek(year = year, week = week)) %&gt;%\n  group_by(cases_cat) %&gt;%\n  mutate(index = seq.int(from = 1, to = length(unique(year_week)))) %&gt;%\n  ungroup() %&gt;%\n  as_tsibble(index = year_week, key = cases_cat)\n\n\nPlot the total number of cases by age group against time. Note that .\n\n\nShow the code\nggplot(data = rota_lg) +\n  geom_point(mapping = aes(x = year_week, y = n), alpha = 0.3) +\n  facet_wrap(facets = vars(cases_cat), \n             scales = \"free_y\") +   \n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(\n    x = \"Year\", \n    y = \"Weekly case counts\",\n    title = \"Rotavirus cases\\n(note differing y scales)\"\n  ) +\n  tsa_theme\n\n\n\n\n\n\n\n\n\nShow the code\n## Notes: \n# You can get line breaks in labels using \\n\n# You can also make all y-axes the same by using scales = \"fixed_y\"\n\n\nWe want to see whether the number of cases changed after the introduction of the vaccine.\nFor that, first we need to state in the dataset when the vaccine was available. Firstly, we are adding one new vaccine variable to the rota_ts time series. It will be 0 for weeks before week 27 2013, and 1 thereafter.\nWe have also created sine and cosine variables so that we can model annual seasonality as before.\n\n\nShow the code\nrota_ts &lt;- rota_lg %&gt;%\n  mutate(\n    vaccine = case_when(\n      year &gt;= 2014 ~ 1,\n      year &lt;= 2012 ~ 0,\n      year == 2013 & week &gt;= 27 ~ 1,\n      year == 2013 & week &lt; 27 ~ 0,\n      TRUE ~ NA_real_\n      ),\n    sin52 = sin(2 * pi * index / 52),\n    cos52 = cos(2 * pi * index / 52)\n  )\n\n## subset to total cases\nrota_ts &lt;- rota_ts %&gt;% \n  filter(cases_cat == \"Total cases\")\n\n\nRun first a separate model for the time before and after the introduction of the vaccine in England and Wales for all population. Can you detect any change in trend?\nNote in the code that we are building further on the tbl_regression function, adding options.\nWhat we saw before:\n\nexponentiate = T to exponentiate coefficients\nstyle_number() to specify the number of digits in the estimates.\nadd_glance_table() to add key parameters at the bottom of the table.\ntable_merge() to take several tables built with tbl_regression and put them in one big table.\n\nWhat we are adding now: - style_pvalue to format the pvalue (here with max 3 digits) - modify_caption to add a table title\n\n\nShow the code\nrotamodel_prevacc_p &lt;- glm(n ~ index,\n    data = rota_ts %&gt;% filter(vaccine == 0),\n    family = \"poisson\"\n) \n\n#If the `summary` command is used for a `glm` Poisson model, the log rate ratios are reported by \n#default. They need to be exponentiated \n\nsummary_rotamodel_prevacc_p &lt;- rotamodel_prevacc_p %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3), \n    estimate_fun = ~style_number(.x, digits = 4)\n    ) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model pre-vaccination - Poisson\")\n  \nsummary_rotamodel_prevacc_p\n\n\n\n\n\n\nRotavirus model pre-vaccination - Poisson\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0028\n1.0027, 1.0029\n&lt;0.001\n\n\nAIC\n78,347\n\n\n\n\n\n\nDeviance\n76,884\n\n\n\n\n\n\nResidual df\n210\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nIs a Poisson model the best option?\nBefore we have a look at the period post-vaccination, is a Poisson model really the best model to use here? We need to check whether our data exhibit overdispersion.\nOverdispersion occurs when the mean of the data is not equal to its variance, violating the fundamental assumption of the Poisson distribution. If this happens, the model underestimates the standard error of the coefficients, biasing results towards narrower confidence intervals and artifically lower p-values.\nLet’s check for overdispersion. We can calculate an overdispersion parameter from a model as the ratio of the deviance and the residuals degrees of freedom. Also, proper statistical test are available, for example using the AER library and the dispersiontest function\n\n\nShow the code\n# Quick check for overdispersion: if check &gt; 1 then use negative binomial\ndeviance &lt;- summary(rotamodel_prevacc_p)$deviance\nresidual.df &lt;- summary(rotamodel_prevacc_p)$df.residual\n\ncheck &lt;- deviance / residual.df\ncheck\n\n\n[1] 366.1138\n\n\nShow the code\n# Proper check for overdispersion: \nAER::dispersiontest(rotamodel_prevacc_p, trafo = NULL, alternative = c(\"greater\"))\n\n\n\n    Overdispersion test\n\ndata:  rotamodel_prevacc_p\nz = 7.2434, p-value = 2.188e-13\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n   446.172 \n\n\nThe overdispersion parameter is fairly greater that 1, and the overdispersion test is significant, so we can safely conclude that a negative binomial model is more appropiate. Let’s compute it with the glm.nb function, and compare with the previous one\n\n\nShow the code\n#so best to use a negative binomial here\nrotamodel_prevacc_nb &lt;- glm.nb(n ~ index,\n                               data = rota_ts %&gt;% filter(vaccine == 0)) \n\n\n# Table with results\nsummary_rotamodel_prevacc_nb &lt;- rotamodel_prevacc_nb %&gt;%\n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)\n    ) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model pre-vaccination - Negative Binomial\")\n  \n\n# Let's compare the two models\ncomparison_p_nb &lt;- gtsummary::tbl_merge(\n  tbls = list(summary_rotamodel_prevacc_p, \n              summary_rotamodel_prevacc_nb),\n  tab_spanner = c(\"Poisson model\", \"Negative Binomial model\")\n  )\n\ncomparison_p_nb\n\n\n\n\n\n\nRotavirus model pre-vaccination - Poisson\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nPoisson model\n\n\nNegative Binomial model\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0028\n1.0027, 1.0029\n&lt;0.001\n1.0029\n1.0005, 1.0054\n0.015\n\n\nAIC\n78,347\n\n\n\n\n2,854\n\n\n\n\n\n\nDeviance\n76,884\n\n\n\n\n248\n\n\n\n\n\n\nResidual df\n210\n\n\n\n\n210\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nThe AIC comparison proves how the negative binomial model outperforms the Poisson model. Also, realize how the index coefficient shifted from a tiny negative to a tiny positive overal trend, and how the p-value has greatly increased (but it still significant)\nLet’s use negative binomial models for the rest of the practical.\nNow let’s look at the period post-introduction of the vaccine.\nWe will fit a model for the post-vaccination period and compare it with the pre-vaccination period\n\n\nShow the code\nrotamodel_postvacc &lt;- glm.nb(n ~ index,\n                             data = rota_ts %&gt;% filter(vaccine == 1))\n\n# Table with results \nsummary_rotamodel_postvacc &lt;- rotamodel_postvacc %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model post-vaccination\")\n\n\n# Comparisson between models\ncomparison_pre_post &lt;- gtsummary::tbl_merge(\n    tbls = list(summary_rotamodel_prevacc_nb, \n                summary_rotamodel_postvacc),\n    tab_spanner = c(\"Pre-vaccination\", \"Post-vaccination\")\n  )\n\ncomparison_pre_post\n\n\n\n\n\n\nRotavirus model pre-vaccination - Negative Binomial\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nPre-vaccination\n\n\nPost-vaccination\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0029\n1.0005, 1.0054\n0.015\n0.9977\n0.9967, 0.9988\n&lt;0.001\n\n\nAIC\n2,854\n\n\n\n\n2,830\n\n\n\n\n\n\nDeviance\n248\n\n\n\n\n293\n\n\n\n\n\n\nResidual df\n210\n\n\n\n\n274\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nWe can see a difference in trends, but the two models cannot be directly compared.\nNow we want to run one single model for both periods (before/after the introduction of the vaccine)\n\n\nShow the code\nrotamodel_trend &lt;- glm.nb(n ~ index + vaccine,\n                          data = rota_ts)\n\n# Table with results\nsummary_rotamodel_trend &lt;- rotamodel_trend %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model with trend and vaccine intervention\")\n\nsummary_rotamodel_trend\n\n\n\n\n\n\nRotavirus model with trend and vaccine intervention\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nindex\n0.9995\n0.9983, 1.0006\n0.341\n\n\nvaccine\n0.2624\n0.1940, 0.3551\n&lt;0.001\n\n\nAIC\n5,768\n\n\n\n\n\n\nDeviance\n544\n\n\n\n\n\n\nResidual df\n485\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nHow would you interpret these results?\nWe can plot the model against the raw data.\n\n\nShow the code\nrota_ts &lt;- rota_ts %&gt;% \n  mutate(fitted_trend = fitted(rotamodel_trend))\n   \n\nggplot(data = rota_ts) +\n  geom_point(mapping = aes(x = year_week, y = n), alpha = 0.3) +\n  geom_line(mapping = aes(x = year_week, y = fitted_trend), \n            alpha = 0.7, colour = \"green\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(x = \"Year\", \n       y = \"Weekly case counts\",\n       title = \"Rotavirus cases: model with trend and intervention\"\n  ) +\n  tsa_theme\n\n\n\n\n\n\n\n\n\nNow we want to run one single model for both periods (before/after the introduction of the vaccine), this time including seasonality.\n\n\nShow the code\nrotamodel_seasonality &lt;- glm.nb(n ~ index + sin52 + cos52 + vaccine,\n                                data = rota_ts)\n\n\nsummary_rotamodel_seasonality &lt;- rotamodel_seasonality %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model with seasonality, trend and vaccine intervention\")\n\nsummary_rotamodel_seasonality\n\n\n\n\n\n\nRotavirus model with seasonality, trend and vaccine intervention\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nindex\n0.9989\n0.9982, 0.9996\n0.001\n\n\nsin52\n0.4245\n0.3951, 0.4560\n&lt;0.001\n\n\ncos52\n2.0527\n1.9092, 2.2071\n&lt;0.001\n\n\nvaccine\n0.4885\n0.4034, 0.5919\n&lt;0.001\n\n\nAIC\n5,225\n\n\n\n\n\n\nDeviance\n506\n\n\n\n\n\n\nResidual df\n483\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nWe can plot the model against the raw data again.\n\n\nShow the code\nrota_ts &lt;- rota_ts %&gt;% \n  mutate(fitted_seasonality = fitted(rotamodel_seasonality))\n \n\nggplot(data = rota_ts) + \n  geom_point(mapping = aes(x = year_week, y = n), alpha = 0.3) +\n  geom_line(mapping = aes(x = year_week, y = fitted_seasonality), \n            alpha = 0.7, colour = \"green\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", \n                   date_breaks = \"1 year\") +\n  labs(x = \"Year\", \n       y = \"Weekly case counts\",\n       title = \"Rotavirus cases: model with trend, seasonality, and intervention\"\n    ) +\n  tsa_theme\n\n\n\n\n\n\n\n\n\nTo be able to comment on any change in trend after the introduction of the vaccine, we need to either include an interaction term in the model or include a time variable that starts at the introduction of the vaccine. Let’s here use an interaction term.\n\n\nShow the code\nrotamodel_winteraction &lt;- glm.nb(n ~ index * vaccine + sin52 + cos52,\n                                 data = rota_ts)\n\nsummary_rotamodel_trendinteraction &lt;- rotamodel_winteraction %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model with seasonality, trend, vaccine and interaction between intervention and trend\")\n\nsummary_rotamodel_trendinteraction\n\n\n\n\n\n\nRotavirus model with seasonality, trend, vaccine and interaction between intervention and trend\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nindex\n1.0015\n1.0003, 1.0027\n0.015\n\n\nvaccine\n0.9833\n0.7076, 1.3693\n0.919\n\n\nsin52\n0.4290\n0.4001, 0.4600\n&lt;0.001\n\n\ncos52\n2.0434\n1.9036, 2.1935\n&lt;0.001\n\n\nindex * vaccine\n0.9962\n0.9948, 0.9977\n&lt;0.001\n\n\nAIC\n5,202\n\n\n\n\n\n\nDeviance\n505\n\n\n\n\n\n\nResidual df\n482\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nYou can visualize the effect of the interaction term using plot_model() from the sjPlot library\n\n\nShow the code\nsjPlot::plot_model(rotamodel_winteraction, type =\"int\") \n\n\n\n\n\n\n\n\n\nHave there been any changes in seasonality, too?\nNote how we can use brackets to introduce interaction terms for several variables.\n\n\nShow the code\nrotamodel_full &lt;- glm.nb(n ~ (sin52 + cos52 + index)*vaccine,\n                         data = rota_ts)\n\n\nsummary_rotamodel_full &lt;- rotamodel_full %&gt;% \n  gtsummary::tbl_regression(\n    exponentiate = TRUE,\n    pvalue_fun = ~style_pvalue(.x, digits = 3),\n    estimate_fun = ~style_number(.x, digits = 4)) %&gt;%\n  gtsummary::add_glance_table(include = c(AIC, deviance, df.residual)) %&gt;% \n  gtsummary::modify_caption(\"Rotavirus model with seasonality, trend, vaccine and interaction term\")\n\nsummary_rotamodel_full\n\n\n\n\n\n\nRotavirus model with seasonality, trend, vaccine and interaction term\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nsin52\n0.2551\n0.2361, 0.2756\n&lt;0.001\n\n\ncos52\n2.1715\n1.9979, 2.3602\n&lt;0.001\n\n\nindex\n1.0006\n0.9997, 1.0016\n0.185\n\n\nvaccine\n0.9175\n0.7086, 1.1897\n0.504\n\n\nsin52 * vaccine\n2.6312\n2.3698, 2.9216\n&lt;0.001\n\n\ncos52 * vaccine\n0.8702\n0.7800, 0.9709\n0.010\n\n\nindex * vaccine\n0.9971\n0.9959, 0.9982\n&lt;0.001\n\n\nAIC\n4,945\n\n\n\n\n\n\nDeviance\n496\n\n\n\n\n\n\nResidual df\n480\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nShow the code\nsjPlot::plot_model(rotamodel_full, type =\"int\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\nLet’s plot the full model estimate.\n\n\nShow the code\nrota_ts &lt;- rota_ts %&gt;% \n  mutate(fitted_full = fitted(rotamodel_full))\n\n\nggplot(data = rota_ts) +\n  geom_point(mapping = aes(x = year_week, y = n), alpha = 0.3) +\n  geom_line(mapping = aes(x = year_week, y = fitted_full), \n            alpha = 0.7, colour = \"green\") +\n  scale_y_continuous(limits = c(0, NA)) +\n  scale_x_yearweek(date_labels = \"%Y-%W\", date_breaks = \"1 year\") +\n  labs(x = \"Year\",\n       y = \"Weekly case counts\",\n       title = \"Rotavirus cases: model with trend, seasonality, intervention \\n and interaction terms\"\n  ) +\n  tsa_theme\n\n\n\n\n\n\n\n\n\nWe can now compare all models next to each other:\n\n\nShow the code\ncomparison_all &lt;- gtsummary::tbl_merge(\n    tbls = list(summary_rotamodel_seasonality,\n                summary_rotamodel_trendinteraction,  \n                summary_rotamodel_full),\n    tab_spanner = c(\"Model without interaction terms\", \n                    \"Interaction with trend only\", \n                    \"Full model\")\n  )\n\ncomparison_all\n\n\n\n\n\n\nRotavirus model with seasonality, trend and vaccine intervention\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nModel without interaction terms\n\n\nInteraction with trend only\n\n\nFull model\n\n\n\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\nIRR\n95% CI\np-value\n\n\n\n\nindex\n0.9989\n0.9982, 0.9996\n0.001\n1.0015\n1.0003, 1.0027\n0.015\n1.0006\n0.9997, 1.0016\n0.185\n\n\nsin52\n0.4245\n0.3951, 0.4560\n&lt;0.001\n0.4290\n0.4001, 0.4600\n&lt;0.001\n0.2551\n0.2361, 0.2756\n&lt;0.001\n\n\ncos52\n2.0527\n1.9092, 2.2071\n&lt;0.001\n2.0434\n1.9036, 2.1935\n&lt;0.001\n2.1715\n1.9979, 2.3602\n&lt;0.001\n\n\nvaccine\n0.4885\n0.4034, 0.5919\n&lt;0.001\n0.9833\n0.7076, 1.3693\n0.919\n0.9175\n0.7086, 1.1897\n0.504\n\n\nAIC\n5,225\n\n\n\n\n5,202\n\n\n\n\n4,945\n\n\n\n\n\n\nDeviance\n506\n\n\n\n\n505\n\n\n\n\n496\n\n\n\n\n\n\nResidual df\n483\n\n\n\n\n482\n\n\n\n\n480\n\n\n\n\n\n\nindex * vaccine\n\n\n\n\n\n\n0.9962\n0.9948, 0.9977\n&lt;0.001\n0.9971\n0.9959, 0.9982\n&lt;0.001\n\n\nsin52 * vaccine\n\n\n\n\n\n\n\n\n\n\n\n\n2.6312\n2.3698, 2.9216\n&lt;0.001\n\n\ncos52 * vaccine\n\n\n\n\n\n\n\n\n\n\n\n\n0.8702\n0.7800, 0.9709\n0.010\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nWhat about age? Can you see a difference in impact of vaccination depending on age category?",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#task-10-2",
    "href": "scripts/10-practical.html#task-10-2",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "Task 10.2 (Optional)",
    "text": "Task 10.2 (Optional)\nDiscuss with colleagues how you can determine the number of cases prevented as a result of the introduction of the vaccine (Hint: refer to Practical 7!).",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/10-practical.html#footnotes",
    "href": "scripts/10-practical.html#footnotes",
    "title": "Practical Session 10: Assessing the impact of interventions using surveillance data",
    "section": "",
    "text": "Rotavirus infant immunisation programme 2014/15: Vaccine uptake report for England (Published: June 2015; PHE publications gateway number: 2015141)↩︎",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 10: Assessing the impact of interventions using surveillance data"
    ]
  },
  {
    "objectID": "scripts/03-practical.html",
    "href": "scripts/03-practical.html",
    "title": "Practical Session 3: Managing date formats and plotting",
    "section": "",
    "text": "Session inject\nYou have been provided with one MS Excel file (tsa_practice.xlsx) containing 2 sheets, one for each of two different diseases (dis1, dis2); and one csv file (tsa_pumala.csv) about Puumala virus infections in Finland.",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 3: Managing date formats and plotting"
    ]
  },
  {
    "objectID": "scripts/03-practical.html#learning-3",
    "href": "scripts/03-practical.html#learning-3",
    "title": "Practical Session 3: Managing date formats and plotting",
    "section": "",
    "text": "Expected Learning Outcomes\nBy the end of the session, participants should be able to:\n\nManage surveillance datasets with different date formats\nCreate specific time series objects using tsibble\nPlot surveillance data against time\n\n\n\nSource code\n\n\nShow the code\n# Install pacman if not installed already, and activate it\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n# Install, update and activate libraries\npacman::p_load(\n  here, \n  rio, \n  skimr,\n  tsibble,\n  ISOweek,\n  tidyverse\n)",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 3: Managing date formats and plotting"
    ]
  },
  {
    "objectID": "scripts/03-practical.html#visualization-exercise",
    "href": "scripts/03-practical.html#visualization-exercise",
    "title": "Practical Session 3: Managing date formats and plotting",
    "section": "3.1 - Visualization exercise",
    "text": "3.1 - Visualization exercise\n\nObjective: to assess visually the reported number of cases of dis1 by ISO (epidemiological) week or calendar month for all the data provided. What diseases do you think dis1 is, judging from the cases’ distribution in time?\n\n\nImport and explore data\nBegin with importing your data to R from these Excel/CSV files and examine them using the well-known str, summary and skim functions\n\n\nShow the code\ndis1 &lt;- import(here(\"data\", \"tsa_practice.xlsx\"), which = \"dis1\")\n\n\nSince we will work with time series data, we could use some time to explore the most relevant variable: date (in this case, the year variable). dis1 is a dataset containing weekly counts of a certain disease between 1981 and 1989. A typical year has 52 weeks, thus we can count the number of times each year appear in the data using table, tabyl or count function, your go-to tools for categorical variables\n\n\nShow the code\ntable(dis1$year)\n\n\n\n1981 1982 1983 1984 1985 1986 1987 1988 1989 \n  52   52   52   52   52   52   52   52   15 \n\n\n\n\nShow the code\njanitor::tabyl(dis1$year)\n\n\n dis1$year  n    percent\n      1981 52 0.12064965\n      1982 52 0.12064965\n      1983 52 0.12064965\n      1984 52 0.12064965\n      1985 52 0.12064965\n      1986 52 0.12064965\n      1987 52 0.12064965\n      1988 52 0.12064965\n      1989 15 0.03480278\n\n\nEach one provides different outputs and possesses unique capabilities. In general, tabyl should be your preferred basic function, thanks to its tidy integration and format output. It also enables some customization and data manipulation.\n\n\nTime series data format\nR has a collection of packages for handling time series data. Some of these packages are part of the tidyverse family of packages. Particularly, it includes the tsibble package, which intends to create a data infrastructure for easier manipulation and handling of temporal data, and adapts the principles of tidy data).\nAccording to the help description, a tsibble object is defined by\n\nAn index, as a variable with inherent ordering from past to present. Mandatory for a ts object\nA key, as a set of variables that define observational units over time, i.e. region, state, age group, etc.. Optional for a ts object\nUniquely identified observations by an index and a key (if defined).\n\nTo convert the original dis1 dataset to a tsibble object, we use the as_tsibble() function and specify the index, i.e. the variable specifying the time unit of interest (year and week variables in our case). We are not using key variables for now. Variables that are not used for index or key purposes, such as the cases variables, are considered as measured variables.\nTo define the index, we can make use of the tsibble built-in functions such as make_yearweek (or yearmonth, yearquarter, etc., see documentation)\n\n\nShow the code\ndis1_ts &lt;- dis1 %&gt;%\n  mutate(date_index = make_yearweek(year = year, week = week)) %&gt;%\n  as_tsibble(index = date_index)\n\nhead(dis1_ts, 5)\n\n\n# A tsibble: 5 x 4 [1W]\n   year  week cases date_index\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;week&gt;\n1  1981     1     1   1981 W01\n2  1981     2     3   1981 W02\n3  1981     3    NA   1981 W03\n4  1981     4     4   1981 W04\n5  1981     5     3   1981 W05\n\n\nYou can see how the number of dis1 cases is distributed in time using the ggplot package.\n\n\nShow the code\nggplot(data = dis1_ts) +\n    geom_line(mapping = aes(x = date_index, y = cases)) +\n    scale_x_yearweek(date_labels = \"%Y\") +\n    labs(x = \"Date\", y = \"Number of Cases\", title = \"Disease 1 data\") +\n    theme_bw() + \n        theme(\n            plot.title = element_text(face = \"bold\", \n                                      size = 12),\n            legend.background = element_rect(fill = \"white\", \n                                             size = 4, \n                                             colour = \"white\"),\n            # legend.justification = c(0, 1),\n            legend.position = \"bottom\",\n            panel.grid.minor = element_blank()\n        )\n\n\n\n\n\n\n\n\n\nOne tip: if you design ggplot themes through more complex theme() customizations, you can save it in an object and later use it in your plots. This way, you only need to write the code once which helps keeping the consistency across your entire plots\n\n\nShow the code\n# We can save theme modifications into a single object and then use it in new plots\ntsa_theme &lt;- theme_bw() + \n        theme(\n            plot.title = element_text(face = \"bold\", \n                                      size = 12),\n            legend.background = element_rect(fill = \"white\", \n                                             size = 4, \n                                             colour = \"white\"),\n            # legend.justification = c(0, 1),\n            legend.position = \"bottom\",\n            panel.grid.minor = element_blank()\n        )\n\n\nNote from the plot that there are missing values in the data.\nIf data points are collected at regular time interval, we can correct missing data by providing a default value or interpolating missing values from other data. The tsibble package has the fill_gaps function, which fills missing values with a pre-specified default value. It is quite common to replaces NAs with its previous observation for each time point in a time series analysis, which is easily done using the fill function from tidyr package.\nA quick overview of implicit missing values with tsibble is available on vignette(\"implicit-na\").\n\n\n\n\n\n\nNote\n\n\n\nFor time series data visualization, there are specific packages and functions you can use. As the focus of this training is on understanding principles of time series analysis rather than visualisation of time series, we will mainly use the ggplot functions for the remaining exercises (also so you get to practise more complex plots)\n\n\n\n\nPumala data\nLet’s now work with the Pumala data\nHere you have one variable for the year, one variable for the month and one variable with the complete date in days, but in a text (chr class) format.\nWith the complete date, you can generate ISO weeks, but first you need the date variable to be converted from text to something R recognises as a date. The lubridate package has a number of convenient functions for converting text strings to dates.\n\n\nShow the code\ndis3 &lt;- dis3 %&gt;%\n  mutate(my_date = dmy(date_str))\n\nstr(dis3$my_date)\n\n\n Date[1:3844], format: \"1995-01-02\" \"1995-01-02\" \"1995-01-03\" \"1995-01-03\" \"1995-01-04\" ...\n\n\nAs a complementary note, check the help for strftime to learn about different date formats in R (?strftime).\nTo convert to ISO week, we can use the ISOweek function from the ISOweek package, which creates a new variable representing the ISO week. We could then also create a new variable representing the first Monday of each ISO week. Although the popular lubridate package has an isoweek function (there is also a similar function in the surveillance package), we use the ISOweek package here as it has the ISOweek2date function. If epidemiological weeks are required, use the EpiWeek package.\nThe paste command concatenates text.\nHere we are adding \"-01\" onto the end of the ISO week variable (which is formatted something like \"1995-W01\"), to indicate that we want the first day of that week, and then supplying that to the ISOweek2date function, which converts that to a date.\nHave a look at the new variables that have been created. date_isowk is the ISO week variable, in string format, and isodate is the Monday of each ISO week. Note that the years 1998 and 2004 each have an ISO week 53.\nYou have several observations in the same week since you have data from different days and one value corresponds to one case. Use the count function to aggregate the data.\n\n\nShow the code\ndis3_v2 &lt;- dis3 %&gt;%\n    count(date_isowk)\n\nhead(dis3_v2)\n\n\n  date_isowk  n\n1   1995-W01 13\n2   1995-W02 15\n3   1995-W03  6\n4   1995-W04  5\n5   1995-W05 11\n6   1995-W06 10\n\n\n\n\nShow the code\ndis3_ts &lt;- dis3_v2 %&gt;%\n    mutate(date_index = yearweek(x = date_isowk, week_start = 1L)) %&gt;%\n    as_tsibble(index = date_index)\n\n\nggplot(data = dis3_ts) +\n    geom_line(mapping = aes(x = date_index, y = n)) +\n    scale_x_yearweek(date_labels = \"%Y\") +\n    labs(x = \"Date\", \n         y = \"Number of Cases\", \n         title = \"Disease 1 data\") +\n    tsa_theme\n\n\n\n\n\n\n\n\n\nAggregating cases by month is another possibility.\n\n\nShow the code\ndis3_agg &lt;- dis3 %&gt;%\n    count(year, month)\n\ndis3_ts_v2 &lt;- dis3_agg %&gt;%\n    mutate(date_index = make_yearmonth(year = year, month = month)) %&gt;%\n    as_tsibble(index = date_index)\n\nggplot(data = dis3_ts_v2) +\n    geom_line(mapping = aes(x = date_index, y = n)) +\n    scale_x_yearweek(date_labels = \"%Y\") +\n    labs(x = \"Date\", \n         y = \"Number of Cases\", \n         title = \"Disease 1 data\") +\n    tsa_theme",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 3: Managing date formats and plotting"
    ]
  },
  {
    "objectID": "scripts/03-practical.html#solution-3-1-1",
    "href": "scripts/03-practical.html#solution-3-1-1",
    "title": "Practical Session 3: Managing date formats and plotting",
    "section": "3.2 Optional task",
    "text": "3.2 Optional task\nImport your data to R from the dis2 excel file.\n\n\nShow the code\ndis2 &lt;- import(here(\"data\", \"tsa_practice.xlsx\"), which = \"dis2\")\nView(dis2)\n\n\nInspect the data.\nYou have separate columns containing the counts. To plot this data, you need to first reshape your dataset by converting it from the current wide format to a long format.\nThe function pivot_longer can perform such transformation.\n\n\nShow the code\ndis2l &lt;- dis2 %&gt;%\n  pivot_longer(\n      cols = -year, \n      names_to = \"month\", \n      values_to = \"case\"\n  ) %&gt;%\n  mutate(month = as_factor(month)) %&gt;%  # as_factor sets levels in the order they appear\n  arrange(year, month)\n\nstr(dis2l)\n\n\ntibble [528 × 3] (S3: tbl_df/tbl/data.frame)\n $ year : num [1:528] 1928 1928 1928 1928 1928 ...\n $ month: Factor w/ 12 levels \"Jan\",\"Feb\",\"Mar\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ case : num [1:528] 609 1516 4952 7466 11155 ...\n\n\nShow the code\nhead(dis2l)\n\n\n# A tibble: 6 × 3\n   year month  case\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1  1928 Jan     609\n2  1928 Feb    1516\n3  1928 Mar    4952\n4  1928 Apr    7466\n5  1928 May   11155\n6  1928 Jun    7002\n\n\nShow the code\ndis2l_agg &lt;- dis2l %&gt;%\n    mutate(date_index = make_yearmonth(year = year, month = month)) %&gt;%\n    as_tsibble(index = date_index)\n\nhead(dis2l_agg)\n\n\n# A tsibble: 6 x 4 [1M]\n   year month  case date_index\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;      &lt;mth&gt;\n1  1928 Jan     609  1928 ene.\n2  1928 Feb    1516  1928 feb.\n3  1928 Mar    4952  1928 mar.\n4  1928 Apr    7466  1928 abr.\n5  1928 May   11155  1928 may.\n6  1928 Jun    7002  1928 jun.\n\n\nShow the code\nggplot(data = dis2l_agg) +\n    geom_line(mapping = aes(x = date_index, y = case)) +\n    scale_x_yearweek(date_labels = \"%Y\") +\n    labs(x = \"Date\", \n         y = \"Number of Cases\", \n         title = \"Disease 3 data\") +\n    tsa_theme\n\n\n\n\n\n\n\n\n\ndis1 corresponds to salmonellosis cases, dis2 to measles cases in New York.",
    "crumbs": [
      "PRACTICALS",
      "Practical Session 3: Managing date formats and plotting"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Analysis (TSA) Module for the ECDC EPIET & EUPHEM Program",
    "section": "",
    "text": "Welcome\nWelcome to the Time Series Analysis (TSA) module webpage of the ECDC EPIET & EUPHEM Program.\nHere you will find the Practical Sessions 3-7, 9 and 10 of the TSA module 2025, including the instructions, guide and solution of the proposed exercises. Sessions 8 and 11 will be provided as stand-alone exercises",
    "crumbs": [
      "HOMEPAGE"
    ]
  },
  {
    "objectID": "index.html#install-r-rtools-and-rstudio",
    "href": "index.html#install-r-rtools-and-rstudio",
    "title": "Time Series Analysis (TSA) Module for the ECDC EPIET & EUPHEM Program",
    "section": "Install R, Rtools and Rstudio",
    "text": "Install R, Rtools and Rstudio\nParticipants need to have R, RTools, and RStudio installed in their computer. Preferably, the installation of these applications should be done in the stated order: R &gt;&gt; RTools &gt;&gt; RStudio. If you don’t have these applications installed yet, please do so following the instructions below:\n\nR should be installed in the participants’ computer. You can download it from here, on the section “Download and Install R”. Select the adequate version to your computer’s operating system.\n\nLatest version available is 4.5.2 (31st Oct 2025). You don’t need the latest version installed. However, it’s highly recommended to stay updated on at least the ‘major version’ (4.x.x) and not too many ‘minor versions’ (x.5.x) away, as packages tend to update to each of them. A warning message might show when using p_load if your R version is older than a package’s last update; however, it will work fine.\nMultiple versions of R can be installed in one’s computer. R usually can be installed without administrative rights. If you have more than one R version installed on your computer, please make sure that you select the specific version 4.2.3. when running RStudio (Top Menu: Settings &gt; Global Options &gt; Left Panel &gt; R)\n\nRTools at the same R version you are using should also be installed in the participants’ computer. You can download the necessary files by clicking here and selecting the corresponding operating system in your computer.\n\nFor MacOS, RTools installation comprises the minimal installation of clang and gfortran as listed in the hyperlinked website. Please note that preferably only one version of RTools version 4.2 or below should be installed in one’s computer. RTools version 4.3 can be installed simultaneously with RTools version 4.2. or below in one’s computer.\n\nRStudio can be used with previous versions without creating conflict with packages or R versions safely. Try to keep updated if possible.",
    "crumbs": [
      "HOMEPAGE"
    ]
  },
  {
    "objectID": "index.html#libraries",
    "href": "index.html#libraries",
    "title": "Time Series Analysis (TSA) Module for the ECDC EPIET & EUPHEM Program",
    "section": "Libraries",
    "text": "Libraries\nThe following R packages have to be installed. Open RStudio, copy the highlighted code below into the R Console pane and press enter. This process might take several minutes.\n\n\nShow the code\n# Install pacman if not installed already, and activate it\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n# Install, update and activate libraries\npacman::p_load(\n  here, \n  rio, \n  skimr,\n  tsibble,\n  ISOweek,\n  slider,\n  pander,\n  season,\n  lmtest,\n  TSA,\n  ciTools,\n  gtsummary,\n  patchwork,\n  AER,\n  MASS,\n  sjPlot,\n  tidyverse\n)\n\n\n## packages to be installed for outbreak detection / loaded by pacman\npacman::p_load(devtools)\ndevtools::install_github(\"United4Surveillance/signal-detection-tool\")\n\n\n## packages to be installed for multilevel / loaded by pacman\npacman::p_load(devtools)\ndevtools::install_github(\"goodekat/redres\")\n\n\nFrequent problems you may encounter during the SignalDetectionTool installation:\n\nPlease start a new R session before the installation by going in Rstudio to Session \n\nSolution: RStudio menu bar &gt; Session &gt; New Session\n\nIn case you get an error message that some package with version x.x.x. is already loaded in the namespace, but a higher version is requested, you should try:\n\nMake a new R session\nIf 1) did not work, then manually install_packages(package_with_problem).\nInstall the SignalDetectionTool again\n\n\nIn case you have troubles accessing Github check below\nInstallation Instructions for the SignalDetectionTool in case of problems with GitHub access\n\nSave the file signal-detection-tool-0.8.0.tar.gz on your computer\nOpen RStudio and run install.packages(\"remotes\")\nInstall all dependencies for the SignalDetectionTool by running and filling in your path to the stored .tar.gz with the command remotes::install_deps(\"your_path_to_signal-detection-tool-0.8.0.tar.gz\"\nInstall the SignalDetectionTool by running install.packages(\"your_path_to_signal-detection-tool-0.8.0.tar.gz\", repos = NULL, type = \"source\")",
    "crumbs": [
      "HOMEPAGE"
    ]
  }
]